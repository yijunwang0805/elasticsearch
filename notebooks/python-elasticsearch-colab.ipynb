{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IsDqz0tsLwZc"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install elasticsearch==7.14.0\n",
        "!apt install default-jdk > /dev/null\n",
        "try:\n",
        "  import os\n",
        "  import elasticsearch\n",
        "  from elasticsearch import Elasticsearch\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  import sys\n",
        "  import json\n",
        "  from ast import literal_eval\n",
        "  from tqdm import tqdm\n",
        "  import datetime\n",
        "  from elasticsearch import helpers\n",
        "\n",
        "except Exception as e:\n",
        "  print(f\"error: {e}\")\n",
        "\n",
        "# Download & extract Elasticsearch 7.0.0\n",
        "\n",
        "!wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.0.0-linux-x86_64.tar.gz -q\n",
        "!tar -xzf elasticsearch-7.0.0-linux-x86_64.tar.gz\n",
        "!chown -R daemon:daemon elasticsearch-7.0.0\n",
        "\n",
        "# Creating daemon instance of elasticsearch\n",
        "import os\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "es_server = Popen(['elasticsearch-7.0.0/bin/elasticsearch'],\n",
        "                  stdout=PIPE, stderr=STDOUT,\n",
        "                  preexec_fn=lambda: os.setuid(1)  # as daemon\n",
        "                 )\n",
        "\n",
        "# This part is important, since it takes a little amount of time for instance to load\n",
        "import time\n",
        "time.sleep(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Bnz8q7BBLv9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ec26f2-ca3f-462c-f9cd-ca8254b6571e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "daemon       957     423  1 22:09 ?        00:00:55 /content/elasticsearch-7.0.0/jdk/bin/java -Xms1g\n",
            "daemon      1043     957  0 22:09 ?        00:00:00 /content/elasticsearch-7.0.0/modules/x-pack-ml/p\n",
            "root       15036   15034  0 23:07 ?        00:00:00 grep elasticsearch\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "# If you get 1 root & 2 daemon process then Elasticsearch instance has started successfully\n",
        "ps -ef | grep elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "k4idJB7WEjY5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "884453da-d365-4813-aa92-a486d753365d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\" : \"6b34e2123210\",\n",
            "  \"cluster_name\" : \"elasticsearch\",\n",
            "  \"cluster_uuid\" : \"6l1WLjtCRgKgalnkfkwHjg\",\n",
            "  \"version\" : {\n",
            "    \"number\" : \"7.0.0\",\n",
            "    \"build_flavor\" : \"default\",\n",
            "    \"build_type\" : \"tar\",\n",
            "    \"build_hash\" : \"b7e28a7\",\n",
            "    \"build_date\" : \"2019-04-05T22:55:32.697037Z\",\n",
            "    \"build_snapshot\" : false,\n",
            "    \"lucene_version\" : \"8.0.0\",\n",
            "    \"minimum_wire_compatibility_version\" : \"6.7.0\",\n",
            "    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n",
            "  },\n",
            "  \"tagline\" : \"You Know, for Search\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Check if elasticsearch is running\n",
        "!curl -sX GET \"localhost:9200/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "dTFy3CkDKk2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b947b4c6-30db-4f8c-93c1-6c001ced2dcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to Elasticsearch\n"
          ]
        }
      ],
      "source": [
        "es = Elasticsearch(hosts = [{\"host\":\"localhost\", \"port\":9200}])\n",
        "# Check if python is connected to elasticsearch\n",
        "if es.ping():\n",
        "    print(\"Connected to Elasticsearch\")\n",
        "else:\n",
        "    print(\"Connection failed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"受持菩萨戒之前需要先受持别解脱戒吗？\"\n",
        "\n",
        "document = \"\"\"\n",
        "无著承许受愿心，无需别解脱戒律，\n",
        "然正受前受七戒，上师询问其违缘，\n",
        "弟子承诺学处等，以愿行各仪轨受。\n",
        "无著菩萨承许，受愿菩提心戒时无须先受别解脱戒，而受行菩提心戒时，必须受七种别解脱戒中的任一者，上师会询问是否具违缘等，弟子在上师面前承诺：从今以后愿意受持所需守持的菩萨学处。承诺守持学处以后，按照愿菩提心和行菩提心各自的仪轨进行受持。\n",
        "无著菩萨的观点：仅仅受愿菩提心戒者，不必先受别解脱戒。但想受行菩提心戒者，在真实受戒前，首先必须受七种别解脱戒。阿底峡尊者在《道灯论》中说：\"别解脱戒律，恒具七种人，菩萨戒有缘，其余不可受。\"受了别解脱戒的人，才有缘受持菩萨戒，其他人不可以受。《大圆满心性休息大车疏》中说，实际按照《道灯论自释》的观点，其他人也可以受，只不过别解脱戒中的一条学处都不能守持的人，没有学菩萨戒的缘分。究竟来讲，龙猛菩萨和无著菩萨的观点无有相违。\n",
        "受戒方式必须依靠仪轨，以断除厌离轮回及贪执寂灭之心、对远离二边的菩提心生起喜悦之情这三种教言改造自心。\n",
        "加行：在殊胜对境前供曼茶罗，诚心祈祷，皈依殊胜所依，以殊胜方便积累资粮。\n",
        "\"\"\"\n",
        "\n",
        "subtitle=\"\"\"\n",
        "菩萨戒不同于别解脱戒别解脱戒只有人可以受持人以外的众生则不能得到别解脱戒的戒体而菩萨戒在受戒者种类方面没有什么限制只要对大乘佛法有信心具有菩提心愿意受菩萨戒任何众生都可以受关于受菩萨戒龙树菩萨和无著菩萨的传承与戒条有些不同按照无著菩萨的要求只有在别解脱戒的基础上才能受菩萨戒而龙树菩萨的传承却没有这样的要求无论如何二者的实质内容是一样的无著菩萨所说的别解脱戒的意思不一定是指别解脱戒的真实戒体而是说必须按照别解脱戒的要求去做断除杀盗淫妄酒等等如果一条戒都不能守而随意杀人偷盗就没有办法受持菩萨戒所以在受菩萨戒之前如果有居士戒那就很完整即使没有受居士戒也不成问题因为受菩萨戒的时候同样也受了不杀生不偷盗等戒条所以没有太大差别最理想的次第是先受居士戒然后精进修持菩提心在自认自己有菩提心时再受持菩萨戒在菩萨戒的基础上再受持密宗誓言——灌顶\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LuL-_k8-i6G-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "import jieba\n",
        "\n",
        "# 连接到Elasticsearch\n",
        "es = Elasticsearch([\"http://localhost:9200\"])\n",
        "\n",
        "# 创建索引和映射\n",
        "index_name = \"buddhism_texts\"\n",
        "es.indices.create(index=index_name, ignore=400)\n",
        "es.indices.put_mapping(index=index_name, body={\n",
        "    \"properties\": {\n",
        "        \"content\": {\n",
        "            \"type\": \"text\",\n",
        "            # \"analyzer\": \"ik_max_word\",\n",
        "            \"analyzer\": \"standard\",\n",
        "            \"search_analyzer\": \"ik_smart\",\n",
        "        }\n",
        "    }\n",
        "})\n",
        "\n",
        "# 索引文档\n",
        "def index_document(content, doc_id):\n",
        "    es.index(index=index_name, id=doc_id, body={\"content\": content})\n",
        "\n",
        "# 分词函数\n",
        "def tokenize(text):\n",
        "    return list(jieba.cut(text))\n",
        "\n",
        "# 搜索函数\n",
        "def search(query):\n",
        "    response = es.search(index=index_name, body={\n",
        "        \"query\": {\n",
        "            \"match\": {\n",
        "                \"content\": query\n",
        "            }\n",
        "        },\n",
        "        \"highlight\": {\n",
        "            \"fields\": {\n",
        "                \"content\": {}\n",
        "            }\n",
        "        }\n",
        "    })\n",
        "    return response['hits']['hits']\n",
        "\n",
        "# 索引测试文档\n",
        "index_document(document, \"doc1\")\n",
        "index_document(subtitle, \"doc2\")\n",
        "\n",
        "# 执行搜索\n",
        "query = \"受持菩萨戒之前需要先受持别解脱戒吗？\"\n",
        "results = search(query)\n",
        "\n",
        "# 输出结果\n",
        "for hit in results:\n",
        "    print(f\"Score: {hit['_score']}\")\n",
        "    print(f\"Content: {hit['_source']['content'][:100]}...\")\n",
        "    print(\"Highlights:\", hit.get('highlight', {}).get('content', []))\n",
        "    print()\n",
        "\n",
        "# 句子级别评分\n",
        "sentences = document.split(\"。\") + subtitle.split(\"。\")\n",
        "for i, sentence in enumerate(sentences):\n",
        "    index_document(sentence, f\"sent{i}\")\n",
        "\n",
        "sentence_results = search(query)\n",
        "print(\"Sentence level scoring:\")\n",
        "for hit in sentence_results[:5]:  # 显示前5个结果\n",
        "    print(f\"Score: {hit['_score']}\")\n",
        "    print(f\"Sentence: {hit['_source']['content']}\")\n",
        "    print()\n",
        "\n",
        "# 短语级别评分\n",
        "phrases = [\" \".join(tokens) for tokens in jieba.cut(document + subtitle)]\n",
        "for i, phrase in enumerate(phrases):\n",
        "    index_document(phrase, f\"phrase{i}\")\n",
        "\n",
        "phrase_results = search(query)\n",
        "print(\"Phrase level scoring:\")\n",
        "for hit in phrase_results[:5]:  # 显示前5个结果\n",
        "    print(f\"Score: {hit['_score']}\")\n",
        "    print(f\"Phrase: {hit['_source']['content']}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSZxpjjLhVaw",
        "outputId": "357a161a-f7d7-44d1-f1b2-3587dd242ddd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba:Building prefix dict from the default dictionary ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence level scoring:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Dumping model to file cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.852 seconds.\n",
            "DEBUG:jieba:Loading model cost 0.852 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "DEBUG:jieba:Prefix dict has been built successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phrase level scoring:\n",
            "Score: 16.248829\n",
            "Phrase: \"受了别解脱戒的人，才有缘受持菩萨戒，其他人不可以受\n",
            "\n",
            "Score: 15.124655\n",
            "Phrase: 受 持\n",
            "\n",
            "Score: 15.124655\n",
            "Phrase: 受 持\n",
            "\n",
            "Score: 15.124655\n",
            "Phrase: 受 持\n",
            "\n",
            "Score: 15.124655\n",
            "Phrase: 受 持\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "python-elasticsearch-colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}